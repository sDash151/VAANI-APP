{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7df75c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Jupyter Notebook Template for ISL Translation\n",
    "# File: training/notebook.ipynb\n",
    "\n",
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Indian Sign Language Translation\\n\",\n",
    "    \"## End-to-End Training and Inference Demo\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import cv2\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from IPython.display import display, HTML\\n\",\n",
    "    \"from app.processing.landmark_extractor import MediaPipeLandmarkExtractor\\n\",\n",
    "    \"from training.dataset import ISLDataset\\n\",\n",
    "    \"from app.models.isl_model import SignLanguageTransformer\\n\",\n",
    "    \"from app.utils.translation_mapper import TranslationMapper\\n\",\n",
    "    \"from training.train import train_model\\n\",\n",
    "    \"from training.evaluate import evaluate_model\\n\",\n",
    "    \"from app.core.config import load_config\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Configuration\\n\",\n",
    "    \"config = load_config()\\n\",\n",
    "    \"extractor = MediaPipeLandmarkExtractor(use_gpu=True)\\n\",\n",
    "    \"translator = TranslationMapper(config.label_mappings)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load sample video\\n\",\n",
    "    \"video_path = \\\"data/samples/hello.mp4\\\"\\n\",\n",
    "    \"cap = cv2.VideoCapture(video_path)\\n\",\n",
    "    \"frames = []\\n\",\n",
    "    \"landmarks_seq = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"while cap.isOpened():\\n\",\n",
    "    \"    ret, frame = cap.read()\\n\",\n",
    "    \"    if not ret:\\n\",\n",
    "    \"        break\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Process frame\\n\",\n",
    "    \"    landmarks = extractor.process(frame)\\n\",\n",
    "    \"    landmarks_seq.append(landmarks)\\n\",\n",
    "    \"    frames.append(frame)\\n\",\n",
    "    \"\\n\",\n",
    "    \"cap.release()\\n\",\n",
    "    \"print(f\\\"Processed {len(frames)} frames\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize landmarks\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"plt.plot(np.array(landmarks_seq)[:, :21*3])  # Plot hand landmarks\\n\",\n",
    "    \"plt.title(\\\"Hand Landmark Trajectories\\\")\\n\",\n",
    "    \"plt.xlabel(\\\"Frame\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"Landmark Position\\\")\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Prepare dataset\\n\",\n",
    "    \"dataset = ISLDataset(\\\"data/train\\\", transform=None)\\n\",\n",
    "    \"print(f\\\"Dataset size: {len(dataset)}\\\")\\n\",\n",
    "    \"print(f\\\"Input shape: {dataset[0][0].shape}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show class distribution\\n\",\n",
    "    \"class_counts = {}\\n\",\n",
    "    \"for _, label in dataset:\\n\",\n",
    "    \"    class_counts[label.item()] = class_counts.get(label.item(), 0) + 1\\n\",\n",
    "    \"    \\n\",\n",
    "    \"plt.bar(class_counts.keys(), class_counts.values())\\n\",\n",
    "    \"plt.title(\\\"Class Distribution\\\")\\n\",\n",
    "    \"plt.xlabel(\\\"Class ID\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"Count\\\")\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train model\\n\",\n",
    "    \"model, history = train_model(\\n\",\n",
    "    \"    train_data_dir=\\\"data/train\\\",\\n\",\n",
    "    \"    val_data_dir=\\\"data/val\\\",\\n\",\n",
    "    \"    epochs=50,\\n\",\n",
    "    \"    batch_size=32,\\n\",\n",
    "    \"    learning_rate=0.001\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot training history\\n\",\n",
    "    \"plt.figure(figsize=(12, 4))\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.plot(history['train_loss'], label='Train Loss')\\n\",\n",
    "    \"plt.plot(history['val_loss'], label='Validation Loss')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.title(\\\"Loss Curves\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"plt.plot(history['train_acc'], label='Train Accuracy')\\n\",\n",
    "    \"plt.plot(history['val_acc'], label='Validation Accuracy')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.title(\\\"Accuracy Curves\\\")\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Run inference\\n\",\n",
    "    \"input_sequence = np.array(landmarks_seq[-config.sequence_length:])\\n\",\n",
    "    \"input_tensor = torch.tensor(input_sequence).unsqueeze(0).float()\\n\",\n",
    "    \"\\n\",\n",
    "    \"with torch.no_grad():\\n\",\n",
    "    \"    output = model(input_tensor)\\n\",\n",
    "    \"    pred_idx = output.argmax().item()\\n\",\n",
    "    \"    confidence = output[0][pred_idx].item()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Prediction: {translator.get_english(pred_idx)} (Hindi: {translator.get_hindi(pred_idx)})\\\")\\n\",\n",
    "    \"print(f\\\"Confidence: {confidence:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create video with prediction overlay\\n\",\n",
    "    \"output_frames = []\\n\",\n",
    "    \"for frame in frames[-30:]:  # Last second of video\\n\",\n",
    "    \"    display_frame = frame.copy()\\n\",\n",
    "    \"    cv2.putText(display_frame, f\\\"Prediction: {translator.get_english(pred_idx)}\\\", \\n\",\n",
    "    \"                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\\n\",\n",
    "    \"    cv2.putText(display_frame, f\\\"Confidence: {confidence:.2f}\\\", \\n\",\n",
    "    \"                (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\\n\",\n",
    "    \"    output_frames.append(display_frame)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save and display result\\n\",\n",
    "    \"output_path = \\\"results/output.mp4\\\"\\n\",\n",
    "    \"frames_to_video(output_frames, output_path, fps=30)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display in notebook\\n\",\n",
    "    \"display(HTML(f\\\"\\\"\\\"\\n\",\n",
    "    \"<video width=\\\"640\\\" height=\\\"480\\\" controls>\\n\",\n",
    "    \"  <source src=\\\"{output_path}\\\" type=\\\"video/mp4\\\">\\n\",\n",
    "    \"</video>\\n\",\n",
    "    \"\\\"\\\"\\\"))\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.18\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
